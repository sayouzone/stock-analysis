{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import tempfile\n",
    "import zipfile\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import (\n",
    "    ConnectionError,\n",
    "\tRetryError,\n",
    "\tRequestException,\n",
    "\tHTTPError,\n",
    "\tTimeout,\n",
    ")\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "PROJECT_ROOT = project_root\n",
    "\n",
    "DATASET_DIR = os.path.join(project_root, 'datasets')\n",
    "\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "\tos.mkdir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c53cf4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_indices(\n",
    "    start_year: int,\n",
    "    end_year: int,\n",
    "    quarters: List[int],\n",
    "    skip_present_indices: bool,\n",
    "    indices_folder: str,\n",
    "    user_agent: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Downloads EDGAR Index files for the specified years and quarters.\n",
    "\n",
    "    Args:\n",
    "            start_year (int): The first year of the indices to be downloaded.\n",
    "            end_year (int): The last year of the indices to be downloaded.\n",
    "            quarters (List[int]): A list of quarters (in the format 1, 2, 3, 4) for which the indices will be downloaded.\n",
    "            skip_present_indices (bool): If True, the function will skip downloading indices that are already present in the directory.\n",
    "            indices_folder (str): Directory where the indices will be saved.\n",
    "            user_agent (str): The User-Agent string that will be declared to SEC EDGAR.\n",
    "\n",
    "    Raises:\n",
    "            ValueError: If an invalid quarter is passed.\n",
    "    \"\"\"\n",
    "\n",
    "    base_url = \"https://www.sec.gov/Archives/edgar/full-index/\"\n",
    "\n",
    "    print(\"Downloading index files from SEC...\")\n",
    "\n",
    "    for quarter in quarters:\n",
    "        if quarter not in [1, 2, 3, 4]:\n",
    "            raise Exception(f'Invalid quarter \"{quarter}\"')\n",
    "    \n",
    "    first_iteration = True\n",
    "    # Loop over the years and quarters to download the indices\n",
    "    while True:\n",
    "        failed_indices = []\n",
    "        for year in range(start_year, end_year+1):\n",
    "            for quarter in quarters:\n",
    "                if year == datetime.now().year and quarter > math.ceil(\n",
    "                    datetime.now().month / 3\n",
    "                ): # Skip future quarters\n",
    "                    break\n",
    "                    \n",
    "                index_filename = f\"{year}_QTR{quarter}.tsv\"\n",
    "\n",
    "                # Check if the index file is already present\n",
    "                if skip_present_indices and os.path.exists(\n",
    "                    os.path.join(indices_folder, index_filename)\n",
    "                ):\n",
    "                    if first_iteration:\n",
    "                        print(f\"Skipping {index_filename}\")\n",
    "                    continue\n",
    "\n",
    "                # If not, download the index file\n",
    "                url = f\"{base_url}/{year}/QTR{quarter}/master.zip\"\n",
    "                \n",
    "                # Retry the download in case of failures\n",
    "                with tempfile.TemporaryFile(mode=\"w+b\") as tmp:\n",
    "                    try:\n",
    "                        request = requests.get(url=url, headers={\"User-agent\": user_agent})\n",
    "                    except Exception as e:\n",
    "                        failed_indices.append(index_filename)\n",
    "                        continue\n",
    "                \n",
    "                    \n",
    "                    tmp.write(request.content)\n",
    "\n",
    "                    with zipfile.ZipFile(tmp).open(\"master.idx\") as f:\n",
    "                        lines = [\n",
    "                            (decoded := line.decode(\"latin-1\")).strip() \n",
    "                            + \"|\" + decoded.split(\"|\")[-1].replace(\".txt\", \"-index.html\")\n",
    "                            for line in itertools.islice(f, 11, None)\n",
    "                        ]\n",
    "\n",
    "                    # Save the processed index file\n",
    "                    with open(\n",
    "                        os.path.join(indices_folder, index_filename),\n",
    "                        \"w+\",\n",
    "                        encoding=\"utf-8\",\n",
    "                    ) as f:\n",
    "                        f.write(\"\".join(lines))\n",
    "                        print(f\"{index_filename} downloaded\")\n",
    "        first_iteration = False\n",
    "        # Handle failed downloads\n",
    "        if len(failed_indices) > 0:\n",
    "            print(f\"Could not download the following indices:\\n{failed_indices}\")\n",
    "            user_input = input(\"Retry (Y/N): \")\n",
    "            if user_input in [\"Y\", \"y\", \"yes\"]:\n",
    "                print(\"Retry downloading failed indices\")\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b55b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Union' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_specific_indices\u001b[39m(\n\u001b[32m      2\u001b[39m     tsv_filenames: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m      3\u001b[39m     filing_types: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m      4\u001b[39m     user_agent: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     cik_tickers: \u001b[43mUnion\u001b[49m[List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m      6\u001b[39m ) -> pd.DataFrame:\n\u001b[32m      7\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    Loops through all the indexes and keeps only the rows/Series for the specific filing types.\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m \u001b[33;03m    Note:\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Initialize list for CIKs\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Union' is not defined"
     ]
    }
   ],
   "source": [
    "def get_specific_indices(\n",
    "    tsv_filenames: List[str],\n",
    "    filing_types: List[str],\n",
    "    user_agent: str,\n",
    "    cik_tickers: Union[List[str], str, None] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loops through all the indexes and keeps only the rows/Series for the specific filing types.\n",
    "\n",
    "    Args:\n",
    "            tsv_filenames (List[str]): The filenames of the indices.\n",
    "            filing_types (List[str]): The filing types to download, e.g., ['10-K', '8-K'].\n",
    "            user_agent (str): The User-Agent string that will be declared to SEC EDGAR.\n",
    "            cik_tickers (Optional[List[str]]): List of CIKs or Tickers. If None, the function processes all CIKs in the provided indices.\n",
    "\n",
    "    Returns:\n",
    "            pd.DataFrame: A dataframe which contains series only for the specific indices.\n",
    "    \n",
    "    Note:\n",
    "            cik_tickers: 타입 힌트 관점에서 Optional 대신 Union이 더 적합함.\n",
    "    \"\"\"\n",
    "    # Initialize list for CIKs\n",
    "    ciks = []\n",
    "    \n",
    "    # cik_tickers 입력값 정규화\n",
    "    target_list = []\n",
    "    # cik_tickers가 제공 되었을 경우\n",
    "    if cik_tickers:\n",
    "        if isinstance(cik_tickers, str):\n",
    "            # 파일 경로인 경우 파일 읽기\n",
    "            if os.path.exists and os.path.isfile(cik_tickers):\n",
    "                with open(cik_tickers) as f:\n",
    "                    cik_tickers = [\n",
    "                        line.strip() for line in f.readlines() if line.strip() != \"\"\n",
    "                    ]\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"File not found: {cik_tickers}\")\n",
    "        \n",
    "        elif isinstance(cik_tickers, List):\n",
    "            target_list = cik_tickers\n",
    "        \n",
    "    # SEC 데이터 다운로드 및 매핑\n",
    "    if target_list:\n",
    "        # Define the company_tickers_url\n",
    "        company_tickers_url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    \n",
    "        try:\n",
    "            request = requests.get(url=company_tickers_url, headers={\"User-agent\": user_agent})\n",
    "        except (\n",
    "            RequestException,\n",
    "            HTTPError,\n",
    "            ConnectionError,\n",
    "            Timeout,\n",
    "            RetryError,\n",
    "        ) as e:\n",
    "            print(f'Failed downloading \"{company_tickers_url}\" - {e}')\n",
    "            raise\n",
    "\n",
    "        # 회사 ticker 데이터 로드\n",
    "        company_tickers = json.load(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad028d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the entire flow of crawling and downloading filings from SEC EDGAR.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Loads the configuration file.\n",
    "    2. Creates necessary directories.\n",
    "    3. Filters out the unnecessary years.\n",
    "    4. Downloads the indices.\n",
    "    5. Gets specific indices according to the provided filing types and CIKs/tickers.\n",
    "    6. Compares the new indices with the old ones to download only the new filings.\n",
    "    7. Crawls through each index to download (.tsv files) and save the filing.\n",
    "\n",
    "    Raises:\n",
    "            SystemExit: If no filing types are provided or if there are no new filings to download.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the configuration file\n",
    "    config_path = os.path.join(PROJECT_ROOT, \"config.json\")\n",
    "    with open(config_path) as fin:\n",
    "        config = json.load(fin)[\"download_filings\"]\n",
    "\n",
    "    # Define the directories and filepaths\n",
    "    raw_filings_folder = os.path.join(DATASET_DIR, config[\"raw_filings_folder\"])\n",
    "    indices_folder = os.path.join(DATASET_DIR, config[\"indices_folder\"])\n",
    "    filings_metadata_filepath = os.path.join(\n",
    "        DATASET_DIR, config[\"filings_metadata_file\"]\n",
    "    )\n",
    "    \n",
    "    # Check if at least one filing type is provided\n",
    "    if len(config[\"filing_types\"]) == 0:\n",
    "        print(\"Please provide at least one filing type\")\n",
    "        exit()\n",
    "\n",
    "    # If the indices and/or download folder doesn't exist, create them\n",
    "    if not os.path.isdir(indices_folder):\n",
    "        os.mkdir(indices_folder)\n",
    "    if not os.path.isdir(raw_filings_folder):\n",
    "        os.mkdir(raw_filings_folder)\n",
    "\n",
    "    # We also create subfolders for each filing type in the raw_filings_folder for better organization\n",
    "    for filing_type in config[\"filing_types\"]:\n",
    "        filing_type_folder = os.path.join(raw_filings_folder, filing_type)\n",
    "        if not os.path.isdir(filing_type_folder):\n",
    "            os.mkdir(filing_type_folder)\n",
    "\n",
    "    # If companies_info.json doesn't exist, create it with empty JSON\n",
    "    if not os.path.isfile(os.path.join(DATASET_DIR, \"companies_info.json\")):\n",
    "        with open(os.path.join(DATASET_DIR, \"companies_info.json\"), \"w\") as f:\n",
    "            json.dump(obj={}, fp=f)\n",
    "    \n",
    "    download_indices(\n",
    "        start_year=config[\"start_year\"],\n",
    "        end_year=config[\"end_year\"],\n",
    "        quarters=config[\"quarters\"],\n",
    "        skip_present_indices=config[\"skip_present_indices\"],\n",
    "        indices_folder=indices_folder,\n",
    "        user_agent=config[\"user_agent\"],\n",
    "    )\n",
    "\n",
    "    tsv_filenames = []\n",
    "    for year in range(config[\"start_year\"], config[\"end_year\"] + 1):\n",
    "        for quarter in config[\"quarters\"]:\n",
    "            filepath = os.path.join(indices_folder, f\"{year}_QTR{quarter}.tsv\")\n",
    "\n",
    "            if os.path.isfile(filepath):\n",
    "                tsv_filenames.append(filepath)\n",
    "\n",
    "    df = get_specific_indices(\n",
    "        tsv_filenames=tsv_filenames,\n",
    "        filing_types=config[\"filing_types\"],\n",
    "        cik_tickers=config[\"cik_tickers\"],\n",
    "        user_agent=config[\"user_agent\"],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
